{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose: Clean and Feature Engineer for a quote to order model and a order to shipment quantity model that will generalize to inputs beyond range of dataset.  \n",
    "#### A closed order is a quote that results in an order within 90 days from the quote date.  \n",
    "#### A shipment is a sale during the 1 year period after the quote closes to an order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This model is designed to work with sparse data and high granularity.  In this case, granulaty is from many part numbers in combination with many customers with intermittent purchases.  No complete time sequences exist due to the granularity.  It can be applied to retail and distribution models as well as demand planning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allow cell to perform multiple computations\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#set cell width as percentage of window\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn_pandas import DataFrameMapper \n",
    "import os as os\n",
    "import string\n",
    "from joblib import dump, load\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data cleaning functions ('parsers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to strip string of leading or following blanks and remove all blank entries ('')\n",
    "\n",
    "def strp_by_col(df,col):#col is with string notation\n",
    "    df[col]=df[col].apply(lambda x: x.lstrip() if type(x)==str else x)\n",
    "    df[col]=df[col].apply(lambda x: x.rstrip() if type(x)==str else x)\n",
    "    df = df[df[col].notnull()] \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean integers with other characters inserted - i.e., keyboard error \n",
    "\n",
    "def clean_ints(entry):\n",
    "    ltr_chars = string.ascii_letters #all letter characters\n",
    "    punct_chars = string.punctuation #all punctuation\n",
    "    proxies = ['!' for ltr in ltr_chars]\n",
    "    proxy_chars = ''.join(map(str,proxies))\n",
    "    puncts = ['!' for p in punct_chars]\n",
    "    proxy_puncts = ''.join(map(str,puncts))\n",
    "    ltr_cleaner = str.maketrans(ltr_chars,proxy_chars)\n",
    "    entry_ltr = entry.translate(ltr_cleaner)\n",
    "    punct_cleaner = str.maketrans(punct_chars,proxy_puncts)\n",
    "    entry_clean = entry_ltr.translate(punct_cleaner)\n",
    "    entry_clean = entry_clean.replace('!','')\n",
    "    return entry_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to strip integer objects of leading spaces, trailing spaces, leading 0, empty strings and clean keyboard errors\n",
    "\n",
    "def str_to_int(db,col):#col is WITH string notation\n",
    "    db[col]=db[col].apply(lambda x: str(x))\n",
    "    db[col]=db[col].apply(lambda x: x.strip())\n",
    "    db[col]=db[col].apply(lambda x: x.lstrip())\n",
    "    db[col]=db[col].apply(lambda x: x.rstrip())\n",
    "    db[col]=db[col].apply(lambda x: clean_ints(x))\n",
    "    db[col]=db[col].apply(lambda x: int(x) if x.isdigit() else None) # to remove empty strings\n",
    "    db = db[db[col].notnull()] #remove rows where cannot convert object to integer\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean floats of inserted characters and punctuation by keyboard error \n",
    "\n",
    "def clean_floats(entry):\n",
    "    ltr_chars = string.ascii_letters #all letter characters\n",
    "    punct_chars = string.punctuation #all punctuation\n",
    "    punct_chars = punct_chars[:13]+punct_chars[15:] # punctuation with decimal point excluded\n",
    "    proxies = ['!' for ltr in ltr_chars]\n",
    "    proxy_chars = ''.join(map(str,proxies))\n",
    "    puncts = ['!' for p in punct_chars]\n",
    "    proxy_puncts = ''.join(map(str,puncts))\n",
    "    ltr_cleaner = str.maketrans(ltr_chars,proxy_chars)\n",
    "    entry_ltr = entry.translate(ltr_cleaner)\n",
    "    punct_cleaner = str.maketrans(punct_chars,proxy_puncts)\n",
    "    entry_clean = entry_ltr.translate(punct_cleaner)\n",
    "    entry_clean = entry_clean.replace('!','')\n",
    "    return entry_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to strip float objects of leading or trailing spaces, leading 0, remove '' and clean keyboard errors\n",
    "\n",
    "def str_to_flt(db,col):#col is WITH string notation\n",
    "    db[col]=db[col].apply(lambda x: str(x))\n",
    "    db[col]=db[col].apply(lambda x: x.strip())\n",
    "    db[col]=db[col].apply(lambda x: x.lstrip())\n",
    "    db[col]=db[col].apply(lambda x: x.rstrip())\n",
    "    db[col]=db[col].apply(lambda x: clean_floats(x))\n",
    "    db[col]=db[col].apply(lambda x: float(x) if x != '' else None)\n",
    "    db = db[db[col].notnull()] # remove rows where cannot convert object to float\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce memory used by integers and floats\n",
    "\n",
    "def reduce_memory_usage(df, verbose=False):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df.loc[:,col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df.loc[:,col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df.loc[:,col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df.loc[:,col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df.loc[:,col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df.loc[:,col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df.loc[:,col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOMAIN KNOWLEDGE:  ship_date is date of a shipment ordered from a valid quote\n",
    "# DOMAIN KNOWLEDGE:  there can be multiple shipments (i.e., multiple ship_date's) against a quote while order is valid\n",
    "# DOMAIN KNOWLEDGE:  quotes are open for ninety days and require a shipment to remain valid\n",
    "# DOMAIN KNOWLEDGE:  quotes remain valid for one year after first ship_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOMAIN KNOWLEDGE: Win is a quote with a shipment against the quote while quote is in 90 day open period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load And Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions:\n",
    "####   'quote' is a unique number assigned to every quote; more than one part can be included on a quote number\n",
    "####   'part' is the part name being quoted\n",
    "####   'plant' is the company division that manufactures the part\n",
    "####   'dist' is a unique number assigned to the company distributors\n",
    "####   'region' is the geographical region \n",
    "####   'quote_qty' is the requested quote amount\n",
    "####   'sales_qty' is the quantity shipped on the 'ship_date'; there can be multiple shipments against a quote\n",
    "####   'quote_price' is the price first quoted; shipping prices can vary from competitive requirements\n",
    "####   'ship_date' are the dates of shipment\n",
    "####   'quote_date' is the date of the quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load order data\n",
    "# path to data file\n",
    "path = os.getcwd()\n",
    "file = '/order_demo_data.csv'\n",
    "filepath = path + file\n",
    "\n",
    "# columns to be read into training and prediction data\n",
    "cols = ['quote', 'part', 'plant', 'dist', 'region', 'quote_qty', 'sales_qty',\n",
    "       'quote_pr', 'ship_date', 'quote_date']\n",
    "\n",
    "# read in data and parse relevant dates\n",
    "dp=pd.read_csv(filepath, usecols=cols, parse_dates=['ship_date','quote_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit historical data to last four years on quote date:  predictions with new data is then one month rolling\n",
    "            # and fit on new data can use previously fit weights from the model\n",
    "    \n",
    "# DOMAIN KNOWLEDGE: prior to this date the client deems the data unreliable\n",
    "\n",
    "# For this exercise set today's date as latest date of quote_date; in production the date would be the current date\n",
    "            # today_date = dt.today() in production version\n",
    "today_date = dp.quote_date.max()\n",
    "\n",
    "# Set earliest date as 48 months previous to current date - any quote before this date is deleted\n",
    "first_date = today_date - pd.DateOffset(months=48)\n",
    "\n",
    "# Keep quote data from today_date to prior 48 months first date\n",
    "dp = dp[(dp['quote_date'] >= first_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assuring data is clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any quote dates == NaT\n",
    "dp = dp[dp.quote_date.notnull()]\n",
    "\n",
    "# Convert integer columns to dtype int  - drop ''\n",
    "dp = str_to_int(dp,'quote')\n",
    "dp = str_to_int(dp,'dist')\n",
    "dp = str_to_int(dp,'quote_qty')\n",
    "dp = str_to_int(dp,'sales_qty')\n",
    "\n",
    "# Convert float or money columns to dtype float - drop ''\n",
    "dp = str_to_flt(dp,'quote_pr')\n",
    "\n",
    "# Strip leading and trailing blanks from string columns\n",
    "dp = strp_by_col(dp,'plant')\n",
    "dp = strp_by_col(dp,'region')\n",
    "\n",
    "# Reduce memory usage from integers and floats\n",
    "dp = reduce_memory_usage(dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply domain knowledge to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOMAIN KNOWLEDGE: negative or zero prices and quantities are either samples or for accounting purposes only\n",
    "\n",
    "# drop zero or negative prices and quantity\n",
    "dp = dp.query('quote_pr > 0 & quote_qty > 0 & sales_qty >= 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOMAIN KNOWLEDGE: prices above $1 per unit are special order designs or accounting adjustments\n",
    "\n",
    "# drop prices over a fixed dollar amount of p\n",
    "p = 1\n",
    "dp = dp[dp['quote_pr'] <= p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clip by percentile of number of events\n",
    "\n",
    "def clip_by_value_count(df,col,limit): #col requires string notation\n",
    " \n",
    "    # Build value_counts dataframe\n",
    "    temp = df[col].value_counts()\n",
    "    temp = pd.DataFrame(temp).reset_index()\n",
    "    temp.columns = [col,'count']\n",
    "\n",
    "    # Computing cumulative percentage\n",
    "    temp['cum_percent'] = 100*(temp['count'].cumsum() / temp['count'].sum())\n",
    "\n",
    "    # Calculate data at clip  limit\n",
    "    temp = temp[temp['cum_percent'] <= limit]\n",
    "    item_list = list(temp[col])\n",
    "    del temp\n",
    "\n",
    "    # Return clipped data\n",
    "    return df[df[col].isin(item_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOMAIN KNOWLEDGE: parts with few transactions are special order designs\n",
    "\n",
    "# this clips the parts quoted to those who make up 80% of the quote transactions\n",
    "dp = clip_by_value_count(dp, 'part', 80)\n",
    "\n",
    "# DOMAIN KNOWLEDGE: distributors with few transactions are soliciting sample quantities or second sourcing small quantities\n",
    "\n",
    "# this clips the distributors to those who make up 80% of the quote transactions\n",
    "dp = clip_by_value_count(dp, 'dist', 80)\n",
    "\n",
    "# DOMAIN KNOWLEDGE: quote qty of less than 200 are courtesy quotes for sales demontration purposes\n",
    "\n",
    "dp = dp[dp.quote_qty > 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Closed, Pending and Expired Quotes by Line Item\n",
    "#### Aggregate by quote number and part number to remove repeated ship dates for a single order/line combination\n",
    "#### Each combination of quote and line are a separate 'quote' that remain 'open' for ninety days\n",
    "#### A 'closed quote' is a quote and line item combination that received a shipping order.  A 'pending quote' is a quote and line item combination that is still within the 90 day period where quotes remain 'open'.  An 'expired quote' is a quote and line item combination that did not received a shipping order before the open period expired. \n",
    "#### The purpose here is to remove repeated ship dates inflating order closing and to identify closed, pending and expired quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to remove multiple shipment dates for a quote and line combination - each line is a unique material\n",
    "# Sum the sold quantity to obtain total quantity sold on the quote for each quote and part\n",
    "# Note that sales_qty summed will convert nan's to 0\n",
    "grps = ['quote','part']  #multiple parts are multiple line items\n",
    "aggs = {'plant':['last'], 'dist':['last'],\n",
    "       'region':['last'], 'quote_qty':['last'], 'sales_qty':['sum'],\n",
    "       'quote_pr':['mean'], 'ship_date':['first'], 'quote_date':['first']}#one dist_num,so_name,div per quote\n",
    "dx = dp.groupby(grps).agg(aggs).reset_index() \n",
    "\n",
    "# flatten multiple index on columns\n",
    "dx.columns = ['_'.join(col) for col in dp.columns.values]\n",
    "\n",
    "# rename columns\n",
    "dx.columns = list(dp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOMAIN KNOWLEDGE:  Top 20% of quote qty receive special management attn for contracting and are not part of the\n",
    "                     #daily operating pricing - or extremely high quote qty are intentional \n",
    "                     #operator error trying to override system\n",
    "\n",
    "# Cap and floor the quote quantity related to the sales quantity\n",
    "# Use the 'capture rate' to measure the relationship between both qty's: capture rate = sales quantity/quote quantity\n",
    "\n",
    "# Insert capture rate into dataframe\n",
    "dx['Capture'] = dx.sales_qty/dx.quote_qty\n",
    "\n",
    "# The 'capture at percentile rank' = limit is the limit 'l'\n",
    "# The median 'capture at percentile rank' = 50 is the median 'm'\n",
    "# Incrs quote quantity to capture at percentile rank * sales quantity when quote_qty less than at 1/p times sales_qty\n",
    "\n",
    "def modify_quote_quantity(dx,target=80):\n",
    "    # Find target percentile of capture rates\n",
    "    dc = dx[dx.Capture > 0]\n",
    "    ul = round(np.percentile(np.array(dc['Capture']).reshape(-1,1),target),1)\n",
    "    ll = round(np.percentile(np.array(dc['Capture']).reshape(-1,1),100-target),1)\n",
    "    \n",
    "    # increase quote_qty to sales_qty times 1/ul when sales_qty is greater than ul times quote_qty\n",
    "    dx['quote_qty'] = np.where(dx['sales_qty'] >= ul * dx['quote_qty'],dx['sales_qty'] * 1/ul,dx['quote_qty'])\n",
    "    \n",
    "    # decrease quote_qty to sales_qty times ll when sales_qty is less than ll time sales quantity\n",
    "    dx['quote_qty'] = np.where((dx['sales_qty'] <= ll * dx['quote_qty']) & (dx['sales_qty'] > 0),dx['sales_qty'] * ll,dx['quote_qty'])\n",
    "        \n",
    "    # convert quote_qty back to ints\n",
    "    dx['quote_qty'] = dx['quote_qty'].apply(lambda q: np.int64(q))\n",
    "    return dx\n",
    "\n",
    "\n",
    "dx = modify_quote_quantity(dx)\n",
    "\n",
    "# Drop 'Capture' from data\n",
    "dx.drop(['Capture'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes of closed, pending and open quotes\n",
    "\n",
    "# Set current and pending dates\n",
    "\n",
    "# For this exercise set today's date as latest date of quote_date; in production the date would be the current date\n",
    "# today_date = dt.today() in production version\n",
    "today_date = dx.quote_date.max()\n",
    "\n",
    "# Set pending date as ninety days previous to current date - any quote on or after this date is still open\n",
    "pending_date = today_date - pd.DateOffset(days=90)\n",
    "\n",
    "# Filter closed and lost quotes\n",
    "closed = dx[dx['sales_qty'] > 0] \n",
    "#pending = dx[(dx['sales_qty'] == 0) & (dx['quote_date'] >= pending_date)]\n",
    "lost = dx[(dx['sales_qty'] == 0) & (dx['quote_date'] < pending_date)]\n",
    "\n",
    "# Concatenate training data of closed and lost quotes\n",
    "dx = pd.concat([closed,lost], axis=0, ignore_index=True)\n",
    "dx.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Wins for closed and lost orders not still pending\n",
    "dx['Win'] = [1 if x > 0 else 0 for x in dx.sales_qty]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert dates to categorical variables\n",
    "# Monthly data is best fit to only Month, Quarter and Year variable\n",
    "\n",
    "def add_date_features(data,date,name):\n",
    "    data[name + 'Yr'] = data[date].dt.year\n",
    "    #data[name + 'DAY'] = data[date].dt.dayofyear\n",
    "    #data[name + 'WK] = data[date].dt.week\n",
    "    data[name + 'Mon'] = data[date].dt.month \n",
    "    data[name + 'Qtr'] = data[date].dt.quarter\n",
    "    #data.drop([date], axis = 1, inplace = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add categorical date features and save for future use\n",
    "\n",
    "dx = add_date_features(dx,'quote_date','Quote_')\n",
    "dx = reduce_memory_usage(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This data is developed for the quote closing predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quote_Order_Data']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save features and targets for quote to order predictor\n",
    "dump (dx,'Quote_Order_Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The quantity predictor requires additional feature engineering\n",
    "#### The ratio of quantity quoted to quantity shipped has extreme anomalies above the 95th percentile\n",
    "#### The quantity predictor only uses the closed quotes to predict quantity shipped\n",
    "#### The data contains shipping quantities for quotes not having reached the closing period of 12 months after the first shipdate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to only include closed quotes ('Wins')\n",
    "ds = dx[dx.Win == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute months elapsed in shipment closing period (12 months after first ship date)\n",
    "\n",
    "# Compute closing date\n",
    "ds['Close_Date'] = ds.ship_date + pd.DateOffset(months=12)\n",
    "\n",
    "# Compute months transpired in shipment closing period\n",
    "ds['Months_Used'] = ((ds.Close_Date - today_date)/np.timedelta64(1,'M')).apply(lambda t: np.int(t))\n",
    "\n",
    "# Convert 0 or negative months to 12\n",
    "ds['Months_Used'] = ds['Months_Used'].apply(lambda t: 12 if t <= 0 else t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values by year, qtr and month for convenience\n",
    "ds = ds.sort_values(by=['Quote_Yr','Quote_Qtr','Quote_Mon'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Order_Ship_Data']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store order to ship data for estimator\n",
    "ds = reduce_memory_usage(ds)\n",
    "dump (ds,'Order_Ship_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_session(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
